{"cells":[{"cell_type":"code","execution_count":null,"id":"fd3b09e5","metadata":{"id":"fd3b09e5","outputId":"a20c1a69-319d-4b2d-f654-5eea515e4399"},"outputs":[{"data":{"text/plain":["'2.10.1'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","tf.__version__"]},{"cell_type":"code","execution_count":null,"id":"e4d52b6f","metadata":{"id":"e4d52b6f","outputId":"0b32478b-9328-4779-84b8-b70bd410a235"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"]},{"data":{"text/plain":["<Policy \"mixed_float16\">"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Turn on mixed precision training\n","from tensorflow.keras import mixed_precision\n","\n","# set global policy to mixed precision\n","mixed_precision.set_global_policy(policy=\"mixed_float16\") \n","\n","# should output \"mixed_float16\" (if your GPU is compatible with mixed precision)\n","mixed_precision.global_policy() "]},{"cell_type":"markdown","id":"92188de9","metadata":{"id":"92188de9"},"source":["## MNT Model to convert English sentences to Vietnamese."]},{"cell_type":"code","execution_count":null,"id":"000ff97e","metadata":{"id":"000ff97e"},"outputs":[],"source":["## Getting Datasets\n","# !curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n","# !curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n","\n","# !curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n","# !curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"]},{"cell_type":"code","execution_count":null,"id":"45c5b6f2","metadata":{"id":"45c5b6f2"},"outputs":[],"source":["max_sentences = 50000"]},{"cell_type":"markdown","id":"958032c3","metadata":{"id":"958032c3"},"source":["### Getting Engish Sentences"]},{"cell_type":"code","execution_count":null,"id":"35cd44e9","metadata":{"id":"35cd44e9"},"outputs":[],"source":["en_sentences = []\n","\n","with open('./train.en', 'r', encoding='utf-8') as file:\n","    for i, each_line in enumerate(file):\n","        \n","        if i < 50:\n","            continue\n","            \n","        if i == max_sentences + 50:\n","            break\n","        # loai bo khoang trang dau va cuoi\n","        sentence_split_by_spaces = each_line.strip()\n","        en_sentences.append(sentence_split_by_spaces)"]},{"cell_type":"markdown","id":"3492f95e","metadata":{"id":"3492f95e"},"source":["### Getting Vietnamese Sentences"]},{"cell_type":"code","execution_count":null,"id":"5ea68a57","metadata":{"id":"5ea68a57"},"outputs":[],"source":["vi_sentences = []\n","\n","with open('./train.vi', 'r', encoding='utf-8') as file:\n","    for i, each_line in enumerate(file):\n","        \n","        if i < 50:\n","            continue\n","            \n","        if i == max_sentences + 50:\n","            break\n","        \n","        sentence_split_by_spaces = each_line.strip()\n","        vi_sentences.append(sentence_split_by_spaces)"]},{"cell_type":"markdown","id":"a6a3ef5b","metadata":{"id":"a6a3ef5b"},"source":["### Insertings tags on the start & end of each sentences"]},{"cell_type":"code","execution_count":null,"id":"e8fb159f","metadata":{"id":"e8fb159f"},"outputs":[],"source":["en_sentences = ['<s> ' + sentence.strip() + ' </s>' for sentence in en_sentences]\n","\n","vi_sentences = ['<s> ' + sentence.strip() + ' </s>' for sentence in vi_sentences]"]},{"cell_type":"markdown","id":"eda4dd51","metadata":{"id":"eda4dd51"},"source":["### Getting samples of sentences"]},{"cell_type":"code","execution_count":null,"id":"de314da9","metadata":{"id":"de314da9","outputId":"0c2f9a17-567a-44fe-d4af-6fbf2c1a160a"},"outputs":[{"name":"stdout","output_type":"stream","text":["<s> In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience . </s>\n","->\n","<s> Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học . </s>\n","\n","\n","\n","<s> And we hand that summary to journalists and policy makers , in order to make headlines like these . </s>\n","->\n","<s> Chúng tôi đưa bản tóm lược cho các nhà báo và nhà chính sách để có được những dòng tít như thế này . </s>\n","\n","\n","\n"]}],"source":["for en, vi in zip(en_sentences[:2], vi_sentences[:2]):\n","    print(en)\n","    print(\"->\")\n","    print(vi)\n","    print(\"\\n\\n\")"]},{"cell_type":"markdown","id":"70404726","metadata":{"id":"70404726"},"source":["### Splitting Dataset"]},{"cell_type":"code","execution_count":null,"id":"07b7190f","metadata":{"id":"07b7190f"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"id":"432397b1","metadata":{"id":"432397b1"},"outputs":[],"source":["train_en_sentences, valid_test_en_sentences, train_vi_sentences, valid_test_vi_sentences = train_test_split(en_sentences, \n","                                                                                                            vi_sentences,\n","                                                                                                            test_size=0.2,\n","                                                                                                            shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"1fe797c6","metadata":{"id":"1fe797c6"},"outputs":[],"source":["valid_en_sentences, test_en_sentences, valid_vi_sentences, test_vi_sentences = train_test_split(valid_test_en_sentences,\n","                                                                                               valid_test_vi_sentences,\n","                                                                                               test_size=0.5,\n","                                                                                               shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"58b1b5dc","metadata":{"id":"58b1b5dc","outputId":"6489e829-9603-4e6a-f8bb-d38ce2ba3269"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of Train set: 40000\n","Shape of Valid set: 5000\n","Shape of Test set: 5000\n"]}],"source":["print(f\"Shape of Train set: {len(train_en_sentences)}\")\n","print(f\"Shape of Valid set: {len(valid_en_sentences)}\")\n","print(f\"Shape of Test set: {len(test_en_sentences)}\")"]},{"cell_type":"markdown","id":"5bddcf2d","metadata":{"id":"5bddcf2d"},"source":["### Getting statistics on How long each sentences are"]},{"cell_type":"code","execution_count":null,"id":"e3568b57","metadata":{"id":"e3568b57","outputId":"bae71bc2-cc5b-43b9-b520-a5d16dd2c3cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lengths of English Sentences:\n"]},{"data":{"text/plain":["count    40000.000000\n","mean        22.005050\n","std         14.303296\n","min          3.000000\n","50%         18.000000\n","75%         28.000000\n","95%         48.000000\n","max        630.000000\n","dtype: float64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["print(\"Lengths of English Sentences:\")\n","pd.Series(train_en_sentences).str.split(\" \").apply(len).describe(percentiles=[0.5, 0.75, 0.95])"]},{"cell_type":"code","execution_count":null,"id":"ac835f29","metadata":{"id":"ac835f29"},"outputs":[],"source":["n_en_seq = 49"]},{"cell_type":"code","execution_count":null,"id":"2d87e161","metadata":{"id":"2d87e161","outputId":"7670d872-2db1-4f7f-fb81-31c0a1c185c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lengths of Vietnamese Sentences:\n"]},{"data":{"text/plain":["count    40000.000000\n","mean        26.611050\n","std         18.136954\n","min          3.000000\n","50%         22.000000\n","75%         33.000000\n","95%         60.000000\n","max        852.000000\n","dtype: float64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(\"Lengths of Vietnamese Sentences:\")\n","pd.Series(train_vi_sentences).str.split(\" \").apply(len).describe(percentiles=[0.5, 0.75, 0.95])"]},{"cell_type":"code","execution_count":null,"id":"26fe55e7","metadata":{"id":"26fe55e7"},"outputs":[],"source":["n_vi_seq = 61"]},{"cell_type":"markdown","id":"f82fe7fa","metadata":{"id":"f82fe7fa"},"source":["### Finding Unique number of Vocabs "]},{"cell_type":"code","execution_count":null,"id":"61fdaad9","metadata":{"id":"61fdaad9","outputId":"66996f62-8d0a-4d4c-e77e-5c2b7e991744"},"outputs":[{"name":"stdout","output_type":"stream","text":["English Vocab:\n","Samples of English words: ['<s>', '</s>', 'Rachel', ':', 'The', 'science', 'behind', 'a', 'climate', 'headline']\n","Size of Engish vocab 17190\n"]}],"source":["print(\"English Vocab:\")\n","\n","en_vocab = []\n","\n","with open(\"./vocab.en\", \"r\", encoding='utf-8') as file:\n","    for i, each_word in enumerate(file):\n","        \n","        # Removing of the unk token\n","        if i == 0:\n","            continue\n","        \n","        en_vocab.append(each_word.strip())\n","\n","        \n","n_en_vocab = len(en_vocab)\n","print(f\"Samples of English words: {en_vocab[:10]}\")\n","print(f\"Size of Engish vocab {n_en_vocab}\")"]},{"cell_type":"code","execution_count":null,"id":"342b192e","metadata":{"id":"342b192e","outputId":"9fc3516a-d0dd-4864-e782-fc6e08a8206a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vietnamese Vocab:\n","Samples of Vietnamese words: ['<s>', '</s>', 'Khoa', 'học', 'đằng', 'sau', 'một', 'tiêu', 'đề', 'về']\n","Size of Vietnamese vocab 7708\n"]}],"source":["print(\"Vietnamese Vocab:\")\n","\n","vi_vocab = []\n","\n","with open(\"./vocab.vi\", \"r\", encoding='utf-8') as file:\n","    for i, each_word in enumerate(file):\n","        \n","        # Removing of the unk token\n","        if i == 0:\n","            continue\n","        \n","        vi_vocab.append(each_word.strip())\n","\n","n_vi_vocab = len(vi_vocab)\n","print(f\"Samples of Vietnamese words: {vi_vocab[:10]}\")\n","print(f\"Size of Vietnamese vocab {n_vi_vocab}\")"]},{"cell_type":"markdown","id":"800d798f","metadata":{"id":"800d798f"},"source":["### Training TextVectorizer Layer"]},{"cell_type":"code","execution_count":null,"id":"192b961f","metadata":{"id":"192b961f"},"outputs":[],"source":["encoder_text_vectorizer = layers.TextVectorization(max_tokens=n_en_vocab,\n","                                                  standardize=None,\n","                                                  split='whitespace',\n","                                                  output_sequence_length=n_en_seq,\n","                                                  name=\"encoder_text_vectorizer_layer\")\n","## Needs to be a numPy array \n","tmp = np.array(train_en_sentences)\n","\n","encoder_text_vectorizer.adapt(tmp)\n","# xây dựng bộ từ vựng từ các chuỗi văn bản trong mảng numpy"]},{"cell_type":"code","execution_count":null,"id":"9836f04e","metadata":{"id":"9836f04e","outputId":"2e610855-bf7e-4b18-b4a6-6d63b8477721"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized Form of \"<s> This is a cat </s>\":\n","\n","[[   3   90   14    9 3905    4    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0]]\n","\n","Samples from layer: ['', '[UNK]', ',', '<s>', '</s>', '.', 'the', 'to', 'of', 'a', 'and', 'that', 'I', 'in', 'is', 'you', 'it', '&apos;s', 'we', 'And']\n"]}],"source":["example = \"<s> This is a cat </s>\"\n","\n","n_en_vocab = len( encoder_text_vectorizer.get_vocabulary() )\n","\n","print(f\"Tokenized Form of \\\"{example}\\\":\\n\\n{encoder_text_vectorizer([example])}\\n\")\n","print(f\"Samples from layer: {encoder_text_vectorizer.get_vocabulary()[:20]}\")"]},{"cell_type":"code","execution_count":null,"id":"53415c9f","metadata":{"id":"53415c9f"},"outputs":[],"source":["decoder_text_vectorizer = layers.TextVectorization(max_tokens=n_vi_vocab,\n","                                                  standardize=None,\n","                                                  split='whitespace',\n","                                                  output_sequence_length=n_vi_seq - 1,\n","                                                  name=\"decoder_text_vectorizer_layer\")\n","## Needs to be a numPy array\n","tmp = np.array(train_vi_sentences)\n","\n","decoder_text_vectorizer.adapt(tmp)"]},{"cell_type":"code","execution_count":null,"id":"1534679c","metadata":{"id":"1534679c","outputId":"571a4133-a29b-4e5f-9595-8c1f8b91e939"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized Form of \"<s> Chúng tôi đưa bản tóm </s>\":\n","\n","[[   2   74    7  259  130 1421    3    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0]]\n","\n","Samples from layer: ['', '[UNK]', '<s>', '</s>', ',', '.', 'là', 'tôi', 'một', 'có', 'và', 'những', 'chúng', 'của', 'ta', 'không', 'bạn', 'đó', 'người', 'trong']\n"]}],"source":["example = \"<s> Chúng tôi đưa bản tóm </s>\"\n","\n","n_vi_vocab = len( decoder_text_vectorizer.get_vocabulary() )\n","\n","print(f\"Tokenized Form of \\\"{example}\\\":\\n\\n{decoder_text_vectorizer([example])}\\n\")\n","print(f\"Samples from layer: {decoder_text_vectorizer.get_vocabulary()[:20]}\")"]},{"cell_type":"markdown","id":"c09c0836","metadata":{"id":"c09c0836"},"source":["### Creating a seq2seq model"]},{"cell_type":"code","execution_count":null,"id":"6f2980a4","metadata":{"id":"6f2980a4"},"outputs":[],"source":["## Encoder\n","encoder_input = layers.Input(shape=(1,) , dtype=tf.string, name=\"encoder_input\")\n","\n","x = encoder_text_vectorizer(encoder_input)\n","x = layers.Embedding(input_dim=n_en_vocab, output_dim=512, mask_zero=True, name=\"encoder_embedding\")(x)\n","x = layers.GRU(256, return_sequences=True, name=\"encoder_gru_1\")(x)\n","x = layers.GRU(256, return_sequences=True, name=\"encoder_gru_2\")(x)\n","\n","encoder_gru_last_layer, encoder_gru_last_state = layers.GRU(256, return_sequences=True, return_state=True, name=\"encoder_gru_last\")(x)\n","\n","\n","encoder_model = tf.keras.models.Model(inputs=encoder_input, outputs=encoder_gru_last_layer, name=\"encoder_model\")\n","\n","## Decoder\n","decoder_input = layers.Input(shape=(1,), dtype=tf.string, name=\"decoder_input\")\n","\n","x = decoder_text_vectorizer(decoder_input)\n","x = layers.Embedding(input_dim=n_vi_vocab, output_dim=512, mask_zero=True, name=\"decoder_embedding\")(x)\n","x = layers.GRU(256, return_sequences=True, name=\"decoder_gru_1\")(x, initial_state=encoder_gru_last_state)\n","x = layers.GRU(256, return_sequences=True, name=\"decoder_gru_2\")(x)\n","x = layers.GRU(256, return_sequences=True, name=\"decoder_gru_last\")(x)\n","x = layers.Dropout(0.5)(x)\n","\n","decoder_out = layers.Dense(n_vi_vocab, activation='softmax')(x)\n","\n","\n","seq2seq = tf.keras.models.Model(inputs=[encoder_model.inputs, decoder_input], outputs=decoder_out)\n","seq2seq.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"cf27df24","metadata":{"id":"cf27df24","outputId":"6a11bb3d-2ac6-4d2e-c748-1179e74349ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 1)]          0           []                               \n","                                                                                                  \n"," encoder_text_vectorizer_layer   (None, 49)          0           ['encoder_input[0][0]']          \n"," (TextVectorization)                                                                              \n","                                                                                                  \n"," encoder_embedding (Embedding)  (None, 49, 512)      8801280     ['encoder_text_vectorizer_layer[0\n","                                                                 ][0]']                           \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 1)]          0           []                               \n","                                                                                                  \n"," encoder_gru_1 (GRU)            (None, 49, 256)      591360      ['encoder_embedding[0][0]']      \n","                                                                                                  \n"," decoder_text_vectorizer_layer   (None, 60)          0           ['decoder_input[0][0]']          \n"," (TextVectorization)                                                                              \n","                                                                                                  \n"," encoder_gru_2 (GRU)            (None, 49, 256)      394752      ['encoder_gru_1[0][0]']          \n","                                                                                                  \n"," decoder_embedding (Embedding)  (None, 60, 512)      3946496     ['decoder_text_vectorizer_layer[0\n","                                                                 ][0]']                           \n","                                                                                                  \n"," encoder_gru_last (GRU)         [(None, 49, 256),    394752      ['encoder_gru_2[0][0]']          \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_gru_1 (GRU)            (None, 60, 256)      591360      ['decoder_embedding[0][0]',      \n","                                                                  'encoder_gru_last[0][1]']       \n","                                                                                                  \n"," decoder_gru_2 (GRU)            (None, 60, 256)      394752      ['decoder_gru_1[0][0]']          \n","                                                                                                  \n"," decoder_gru_last (GRU)         (None, 60, 256)      394752      ['decoder_gru_2[0][0]']          \n","                                                                                                  \n"," dropout (Dropout)              (None, 60, 256)      0           ['decoder_gru_last[0][0]']       \n","                                                                                                  \n"," dense (Dense)                  (None, 60, 7708)     1980956     ['dropout[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 17,490,460\n","Trainable params: 17,490,460\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["seq2seq.summary()"]},{"cell_type":"markdown","id":"3f449480","metadata":{"id":"3f449480"},"source":["### Preparing data for model"]},{"cell_type":"code","execution_count":null,"id":"bf3df5bd","metadata":{"id":"bf3df5bd"},"outputs":[],"source":["def prepare_data(X, y, tensor=False, batch_size=128):\n","    \n","    encoder_input =  np.array( X )\n","    decoder_input = np.array( [\" \".join(sentence.split(\" \")[:-1]) for sentence in y] )\n","    \n","    decoder_labels = [\" \".join(sentence.split(\" \")[1:]) for sentence in y]\n","    decoder_labels = decoder_text_vectorizer(decoder_labels).numpy()\n","    \n","    if tensor:\n","        encoder_input = tf.data.Dataset.from_tensor_slices(encoder_input)\n","        decoder_input = tf.data.Dataset.from_tensor_slices(decoder_input)\n","        decoder_labels = tf.data.Dataset.from_tensor_slices(decoder_labels)\n","        \n","        inputs = tf.data.Dataset.zip( (encoder_input, decoder_input) )\n","        labels = tf.data.Dataset.zip( (inputs, decoder_labels) ).batch(batch_size=batch_size).prefetch(tf.data.AUTOTUNE).cache()\n","        \n","        return labels, None\n","    \n","    return (encoder_input, decoder_input), decoder_labels"]},{"cell_type":"code","execution_count":null,"id":"9c927d68","metadata":{"id":"9c927d68"},"outputs":[],"source":["batch_size = 512"]},{"cell_type":"code","execution_count":null,"id":"add136f5","metadata":{"id":"add136f5"},"outputs":[],"source":["train_features, train_labels = prepare_data(train_en_sentences, train_vi_sentences, tensor=True)\n","valid_features, valid_labels = prepare_data(valid_en_sentences, valid_vi_sentences, tensor=True)\n","test_features, test_labels = prepare_data(test_en_sentences, test_vi_sentences, tensor=True)"]},{"cell_type":"markdown","id":"c64a77a2","metadata":{"id":"c64a77a2"},"source":["### Training the model"]},{"cell_type":"code","execution_count":null,"id":"2fb65def","metadata":{"id":"2fb65def","outputId":"06390fec-1b98-484a-9af2-77ce52782706"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","313/313 [==============================] - 74s 166ms/step - loss: 2.6322 - accuracy: 0.0471 - val_loss: 2.5719 - val_accuracy: 0.0664 - lr: 0.0010\n","Epoch 2/100\n","313/313 [==============================] - 43s 136ms/step - loss: 2.5409 - accuracy: 0.0750 - val_loss: 2.5236 - val_accuracy: 0.0887 - lr: 0.0010\n","Epoch 3/100\n","313/313 [==============================] - 43s 138ms/step - loss: 2.5084 - accuracy: 0.0963 - val_loss: 2.5100 - val_accuracy: 0.0968 - lr: 0.0010\n","Epoch 4/100\n","313/313 [==============================] - 43s 137ms/step - loss: 2.4893 - accuracy: 0.1025 - val_loss: 2.4842 - val_accuracy: 0.0999 - lr: 0.0010\n","Epoch 5/100\n","313/313 [==============================] - 43s 137ms/step - loss: 2.4631 - accuracy: 0.1065 - val_loss: 2.4584 - val_accuracy: 0.0999 - lr: 0.0010\n","Epoch 6/100\n","313/313 [==============================] - 43s 136ms/step - loss: 2.4382 - accuracy: 0.1085 - val_loss: 2.4035 - val_accuracy: 0.1167 - lr: 0.0010\n","Epoch 7/100\n","313/313 [==============================] - 43s 139ms/step - loss: 2.3818 - accuracy: 0.1176 - val_loss: 2.3291 - val_accuracy: 0.1267 - lr: 0.0010\n","Epoch 8/100\n","313/313 [==============================] - 44s 139ms/step - loss: 2.3122 - accuracy: 0.1288 - val_loss: 2.2585 - val_accuracy: 0.1406 - lr: 0.0010\n","Epoch 9/100\n","313/313 [==============================] - 43s 138ms/step - loss: 2.2422 - accuracy: 0.1407 - val_loss: 2.1863 - val_accuracy: 0.1573 - lr: 0.0010\n","Epoch 10/100\n","313/313 [==============================] - 42s 135ms/step - loss: 2.1828 - accuracy: 0.1534 - val_loss: 2.1202 - val_accuracy: 0.1734 - lr: 0.0010\n","Epoch 11/100\n","313/313 [==============================] - 43s 137ms/step - loss: 2.1160 - accuracy: 0.1707 - val_loss: 2.0481 - val_accuracy: 0.1974 - lr: 0.0010\n","Epoch 12/100\n","313/313 [==============================] - 43s 138ms/step - loss: 2.0391 - accuracy: 0.1950 - val_loss: 1.9791 - val_accuracy: 0.2193 - lr: 0.0010\n","Epoch 13/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.9716 - accuracy: 0.2155 - val_loss: 1.9234 - val_accuracy: 0.2356 - lr: 0.0010\n","Epoch 14/100\n","313/313 [==============================] - 43s 136ms/step - loss: 1.9159 - accuracy: 0.2322 - val_loss: 1.8809 - val_accuracy: 0.2466 - lr: 0.0010\n","Epoch 15/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.8716 - accuracy: 0.2450 - val_loss: 1.8486 - val_accuracy: 0.2538 - lr: 0.0010\n","Epoch 16/100\n","313/313 [==============================] - 43s 136ms/step - loss: 1.8348 - accuracy: 0.2545 - val_loss: 1.8288 - val_accuracy: 0.2561 - lr: 0.0010\n","Epoch 17/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.8022 - accuracy: 0.2627 - val_loss: 1.8084 - val_accuracy: 0.2651 - lr: 0.0010\n","Epoch 18/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.7742 - accuracy: 0.2701 - val_loss: 1.7892 - val_accuracy: 0.2744 - lr: 0.0010\n","Epoch 19/100\n","313/313 [==============================] - 43s 138ms/step - loss: 1.7493 - accuracy: 0.2775 - val_loss: 1.7613 - val_accuracy: 0.2827 - lr: 0.0010\n","Epoch 20/100\n","313/313 [==============================] - 43s 136ms/step - loss: 1.7244 - accuracy: 0.2845 - val_loss: 1.7452 - val_accuracy: 0.2882 - lr: 0.0010\n","Epoch 21/100\n","313/313 [==============================] - 43s 136ms/step - loss: 1.7008 - accuracy: 0.2911 - val_loss: 1.7353 - val_accuracy: 0.2913 - lr: 0.0010\n","Epoch 22/100\n","313/313 [==============================] - 43s 138ms/step - loss: 1.6809 - accuracy: 0.2962 - val_loss: 1.7317 - val_accuracy: 0.2934 - lr: 0.0010\n","Epoch 23/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.6628 - accuracy: 0.3010 - val_loss: 1.7277 - val_accuracy: 0.2955 - lr: 0.0010\n","Epoch 24/100\n","313/313 [==============================] - 45s 143ms/step - loss: 1.6433 - accuracy: 0.3057 - val_loss: 1.7166 - val_accuracy: 0.2965 - lr: 0.0010\n","Epoch 25/100\n","313/313 [==============================] - 44s 141ms/step - loss: 1.6252 - accuracy: 0.3103 - val_loss: 1.7145 - val_accuracy: 0.2971 - lr: 0.0010\n","Epoch 26/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.6089 - accuracy: 0.3148 - val_loss: 1.7068 - val_accuracy: 0.3000 - lr: 0.0010\n","Epoch 27/100\n","313/313 [==============================] - 43s 138ms/step - loss: 1.5948 - accuracy: 0.3182 - val_loss: 1.7177 - val_accuracy: 0.3019 - lr: 0.0010\n","Epoch 28/100\n","313/313 [==============================] - 43s 138ms/step - loss: 1.5820 - accuracy: 0.3216 - val_loss: 1.7161 - val_accuracy: 0.3009 - lr: 0.0010\n","Epoch 29/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.5699 - accuracy: 0.3245 - val_loss: 1.6924 - val_accuracy: 0.3040 - lr: 0.0010\n","Epoch 30/100\n","313/313 [==============================] - 43s 136ms/step - loss: 1.5550 - accuracy: 0.3283 - val_loss: 1.6995 - val_accuracy: 0.2977 - lr: 0.0010\n","Epoch 31/100\n","313/313 [==============================] - 43s 138ms/step - loss: 1.5406 - accuracy: 0.3328 - val_loss: 1.6993 - val_accuracy: 0.2971 - lr: 0.0010\n","Epoch 32/100\n","313/313 [==============================] - 43s 137ms/step - loss: 1.5275 - accuracy: 0.3354 - val_loss: 1.6992 - val_accuracy: 0.3005 - lr: 0.0010\n","Epoch 33/100\n","313/313 [==============================] - 42s 135ms/step - loss: 1.5191 - accuracy: 0.3383 - val_loss: 1.6959 - val_accuracy: 0.3049 - lr: 0.0010\n","Epoch 34/100\n","313/313 [==============================] - ETA: 0s - loss: 1.5069 - accuracy: 0.3414\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","313/313 [==============================] - 41s 132ms/step - loss: 1.5069 - accuracy: 0.3414 - val_loss: 1.7031 - val_accuracy: 0.3034 - lr: 0.0010\n"]}],"source":["epochs = 100\n","\n","early_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n","learning_rate_callback =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, min_lr=0.000001)\n","\n","history = seq2seq.fit(train_features,\n","                      epochs=epochs, \n","                      batch_size=batch_size,\n","                     validation_batch_size=batch_size,\n","                     validation_data=valid_features,\n","                     callbacks=[early_callback, learning_rate_callback])"]},{"cell_type":"code","execution_count":null,"id":"accd45fc","metadata":{"id":"accd45fc","outputId":"f842c6c3-38eb-4ec9-f65f-4a1ecabd3a0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["40/40 [==============================] - 2s 56ms/step - loss: 1.6858 - accuracy: 0.3044\n"]},{"data":{"text/plain":["[1.6858359575271606, 0.30438748002052307]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["seq2seq.evaluate(test_features)"]},{"cell_type":"code","execution_count":null,"id":"92c7cc3e","metadata":{"id":"92c7cc3e","outputId":"7fb8f66e-5f9b-4801-f6e5-93a86ecdeb3e"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./saved_models/seq2seq/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./saved_models/seq2seq/assets\n"]}],"source":["seq2seq.save(\"./saved_models/seq2seq/\")"]},{"cell_type":"markdown","id":"5e84732e","metadata":{"id":"5e84732e"},"source":["### Inference Model"]},{"cell_type":"code","execution_count":null,"id":"f3cfeb1b","metadata":{"id":"f3cfeb1b"},"outputs":[],"source":["## Encoder\n","encoder_input = layers.Input(shape=(1,) , dtype=tf.string, name=\"encoder_input\")\n","\n","x = seq2seq.get_layer(\"encoder_text_vectorizer_layer\")(encoder_input)\n","x = seq2seq.get_layer(\"encoder_embedding\")(x)\n","x = seq2seq.get_layer(\"encoder_gru_1\")(x)\n","x = seq2seq.get_layer(\"encoder_gru_2\")(x)\n","\n","encoder_gru_last_layer, encoder_gru_last_state = seq2seq.get_layer(\"encoder_gru_last\")(x)\n","\n","\n","encoder_model = tf.keras.models.Model(inputs=encoder_input, outputs=[encoder_gru_last_layer, encoder_gru_last_state], name=\"encoder_model\")\n","\n","\n","## Decoder\n","decoder_input = layers.Input(shape=(1,), dtype=tf.string, name=\"decoder_input\")\n","decoder_encoder_state = layers.Input(shape=(256,))\n","\n","x = seq2seq.get_layer(\"decoder_text_vectorizer_layer\")(decoder_input)\n","x = seq2seq.get_layer(\"decoder_embedding\")(x)\n","\n","gru_1 = layers.GRU(256, return_sequences=True, name=\"decoder_gru_1\", dtype='float')\n","x = gru_1(x, initial_state=decoder_encoder_state)\n","\n","gru_2 = layers.GRU(256, return_sequences=True, name=\"decoder_gru_2\", dtype='float')\n","x = gru_2(x, initial_state=decoder_encoder_state)\n","\n","decoder_gru_last_layer = layers.GRU(256, return_sequences=True, name=\"decoder_gru_last\")\n","gru_out = decoder_gru_last_layer(x)\n","\n","decoder_out = seq2seq.get_layer(\"dense\")(gru_out)\n","\n","\n","inference_model = tf.keras.models.Model(inputs=[decoder_input, decoder_encoder_state], outputs=[decoder_out, gru_out])\n","inference_model.compile()\n","\n","gru_1.set_weights(seq2seq.get_layer(\"decoder_gru_1\").get_weights())\n","gru_2.set_weights(seq2seq.get_layer(\"decoder_gru_2\").get_weights())\n","decoder_gru_last_layer.set_weights(seq2seq.get_layer(\"decoder_gru_last\").get_weights())"]},{"cell_type":"code","execution_count":null,"id":"9a1ceafc","metadata":{"id":"9a1ceafc","outputId":"cc67d0ed-b93c-44af-8284-414d89cf85e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," decoder_input (InputLayer)     [(None, 1)]          0           []                               \n","                                                                                                  \n"," decoder_text_vectorizer_layer   (None, 60)          0           ['decoder_input[0][0]']          \n"," (TextVectorization)                                                                              \n","                                                                                                  \n"," decoder_embedding (Embedding)  (None, 60, 512)      3946496     ['decoder_text_vectorizer_layer[1\n","                                                                 ][0]']                           \n","                                                                                                  \n"," input_1 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," decoder_gru_1 (GRU)            (None, 60, 256)      591360      ['decoder_embedding[1][0]',      \n","                                                                  'input_1[0][0]']                \n","                                                                                                  \n"," decoder_gru_2 (GRU)            (None, 60, 256)      394752      ['decoder_gru_1[0][0]',          \n","                                                                  'input_1[0][0]']                \n","                                                                                                  \n"," decoder_gru_last (GRU)         (None, 60, 256)      394752      ['decoder_gru_2[0][0]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 60, 7708)     1980956     ['decoder_gru_last[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,308,316\n","Trainable params: 7,308,316\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["inference_model.summary()"]},{"cell_type":"code","execution_count":null,"id":"904a3d71","metadata":{"id":"904a3d71"},"outputs":[],"source":["# inference_model.save(\"/saved_models/inference_model/\")"]},{"cell_type":"code","execution_count":null,"id":"0c261da8","metadata":{"id":"0c261da8"},"outputs":[],"source":["word_ids_to_word = {key:value for key, value in enumerate(decoder_text_vectorizer.get_vocabulary())}"]},{"cell_type":"code","execution_count":null,"id":"2a794b7e","metadata":{"id":"2a794b7e"},"outputs":[],"source":["def generate_translation(english_text):\n","    \n","    #Generate content vector\n","    encoder_gru_last_layer, content_vector = encoder_model( np.array(english_text) )\n","    \n","    #y_pred. Starting value <s>\n","    y_pred = np.array([[\"<s>\"]])\n","    predicted_sentence = ['<s>']\n","    \n","    for _ in range(100):\n","        \n","        if y_pred[0][0] == '</s>':\n","            break\n","            \n","        softmax_probability, content_vector = inference_model.predict([y_pred, content_vector], verbose=0)\n","        # why\n","        content_vector = content_vector[:, 0, :]\n","        # Perform argmax on the last axis & get the highest value\n","        softmax_prediction = np.argmax(softmax_probability, axis=-1).ravel()[0]\n","        y_pred = np.array([[word_ids_to_word[softmax_prediction]]])\n","        \n","        predicted_sentence.append( word_ids_to_word[softmax_prediction] )\n","    \n","    return \" \".join(predicted_sentence)"]},{"cell_type":"code","execution_count":null,"id":"013bf66b","metadata":{"id":"013bf66b","outputId":"1ed7dd15-cff7-4bb4-a593-13f15d0bf666"},"outputs":[{"data":{"text/plain":["'<s> Xin thể Schwarzchild lại tôi </s>'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["text = '<s> welcome everyone </s>'\n","\n","generate_translation([text])"]},{"cell_type":"code","execution_count":null,"id":"c11771f5","metadata":{"id":"c11771f5"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}